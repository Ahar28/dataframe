{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-14T09:26:20.743865352Z",
     "start_time": "2023-09-14T09:23:09.307742276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received properties: Properties: {spark=3.3.1, scala=2.13, v=1.2.3, displayLimit=20, displayTruncate=30, spark.app.name=Jupyter, spark.master=local[*], spark.sql.codegen.wholeStage=false, fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem, fs.file.impl=org.apache.hadoop.fs.LocalFileSystem}, providing Spark with: {spark.app.name=Jupyter, spark.master=local[*], spark.sql.codegen.wholeStage=false, fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem, fs.file.impl=org.apache.hadoop.fs.LocalFileSystem}\n",
      "Spark session (Spark: 3.3.1, Scala: 2.13, v: 1.2.3)  has been started and is running. No `withSpark { }` necessary, you can access `spark` and `sc` directly. To use Spark streaming, use `%use spark-streaming` instead.\n"
     ]
    }
   ],
   "source": [
    "%use spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%use dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T09:28:53.814099513Z",
     "start_time": "2023-09-14T09:28:43.500458642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------+------+-------+\n",
      "|              name|age|  city|weight|isHappy|\n",
      "+------------------+---+------+------+-------+\n",
      "|   {Alice, Cooper}| 15|London|    54|   true|\n",
      "|      {Bob, Dylan}| 45| Dubai|    87|   true|\n",
      "|{Charlie, Daniels}| 20|Moscow|  null|  false|\n",
      "|{Charlie, Chaplin}| 40| Milan|  null|   true|\n",
      "|     {Bob, Marley}| 30| Tokyo|    68|   true|\n",
      "|     {Alice, Wolf}| 20|  null|    55|  false|\n",
      "|   {Charlie, Byrd}| 30|Moscow|    90|   true|\n",
      "+------------------+---+------+------+-------+\n"
     ]
    }
   ],
   "source": [
    "@DataSchema\n",
    "data class Name(\n",
    "    val firstName: String,\n",
    "    val lastName: String,\n",
    ")\n",
    "\n",
    "@DataSchema\n",
    "data class Person(\n",
    "    val name: Name,\n",
    "    val age: Int,\n",
    "    val city: String?,\n",
    "    val weight: Int?,\n",
    "    val isHappy: Boolean,\n",
    ")\n",
    "\n",
    "val df: DataFrame<Person> = listOf(\n",
    "    Person(Name(\"Alice\", \"Cooper\"), 15, \"London\", 54, true),\n",
    "    Person(Name(\"Bob\", \"Dylan\"), 45, \"Dubai\", 87, true),\n",
    "    Person(Name(\"Charlie\", \"Daniels\"), 20, \"Moscow\", null, false),\n",
    "    Person(Name(\"Charlie\", \"Chaplin\"), 40, \"Milan\", null, true),\n",
    "    Person(Name(\"Bob\", \"Marley\"), 30, \"Tokyo\", 68, true),\n",
    "    Person(Name(\"Alice\", \"Wolf\"), 20, null, 55, false),\n",
    "    Person(Name(\"Charlie\", \"Byrd\"), 30, \"Moscow\", 90, true),\n",
    ").toDataFrame()\n",
    "\n",
    "//DISPLAY(df)\n",
    "\n",
    "val sparkDs = df.\n",
    "\n",
    "sparkDs.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T09:45:21.290504872Z",
     "start_time": "2023-09-14T09:45:20.271710995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "fun DataFrame<*>.toSpark(): Dataset<Row> {\n",
    "    val rows = rows().map { row ->\n",
    "        RowFactory.create(*row.values().toTypedArray())\n",
    "    }\n",
    "    return rows.toDF()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T09:52:07.878648515Z",
     "start_time": "2023-09-14T09:52:07.604005846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[[{ firstName:Alice, lastName:Cooper },15,London,54,true], [{ firstName:Bob, lastName:Dylan },45,Dubai,87,true], [{ firstName:Charlie, lastName:Daniels },20,Moscow,null,false], [{ firstName:Charlie, lastName:Chaplin },40,Milan,null,true], [{ firstName:Bob, lastName:Marley },30,Tokyo,68,true], [{ firstName:Alice, lastName:Wolf },20,null,55,false], [{ firstName:Charlie, lastName:Byrd },30,Moscow,90,true]]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rows = df.rows().map { row ->\n",
    "    RowFactory.create(*row.values().toTypedArray())\n",
    "}\n",
    "DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T09:53:16.574948021Z",
     "start_time": "2023-09-14T09:53:16.370067190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.8.20",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
